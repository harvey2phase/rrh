{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "RRH_MNIST.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "bxImy1XR6FHR"
      ],
      "authorship_tag": "ABX9TyNHZmYzXge3IPHLWnfgVF+L"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "nlBt0FWz8iXu"
      },
      "source": [
        "import os\n",
        "import urllib\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v6LIvWHvxHV3"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as functional\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision.datasets import MNIST"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cuXs60E66A8k"
      },
      "source": [
        "# Definitions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kAg4fEcS9156"
      },
      "source": [
        "## Variational Autoencoder (VAE)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DoZjwrH3xpei"
      },
      "source": [
        "LAT_DIM = 2\n",
        "EPOCH_NUM = 50\n",
        "BATCH_SIZE = 128\n",
        "CAPACITY = 64\n",
        "LRN_RATE = 1e-3\n",
        "VAR_BETA = 1\n",
        "\n",
        "KERN_SIZE = 4\n",
        "STRIDE = 2\n",
        "PAD = 1\n",
        "\n",
        "GPU = True"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UkcWN5LXyCEo"
      },
      "source": [
        "class Encoder(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Encoder, self).__init__()\n",
        "        \n",
        "        # CAPACITY * 14 * 14\n",
        "        self.conv1 = nn.Conv2d(\n",
        "            in_channels = 1,\n",
        "            out_channels = CAPACITY,\n",
        "            kernel_size = KERN_SIZE,\n",
        "            stride = STRIDE,\n",
        "            padding = PAD,\n",
        "        )\n",
        "        # CAPACITY * 7 * 7\n",
        "        self.conv2 = nn.Conv2d(\n",
        "            in_channels = CAPACITY,\n",
        "            out_channels = CAPACITY * 2,\n",
        "            kernel_size = KERN_SIZE,\n",
        "            stride = STRIDE,\n",
        "            padding = PAD,\n",
        "        )\n",
        "        self.fc_mu = nn.Linear(\n",
        "            in_features = CAPACITY * 2 * 7 * 7,\n",
        "            out_features = LAT_DIM,\n",
        "        )\n",
        "        self.fc_logvar = nn.Linear(\n",
        "            in_features = CAPACITY * 2 * 7 * 7,\n",
        "            out_features = LAT_DIM,\n",
        "        )\n",
        "        \n",
        "    def forward(self, x):\n",
        "        x = functional.relu(self.conv2(\n",
        "            functional.relu(self.conv1(x))\n",
        "        ))\n",
        "        x = x.view(x.size(0), -1)\n",
        "        x_mu = self.fc_mu(x)\n",
        "        x_logvar = self.fc_logvar(x)\n",
        "        return x_mu, x_logvar"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "35jQ8f41zRFg"
      },
      "source": [
        "class Decoder(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Decoder, self).__init__()\n",
        "        \n",
        "        self.fc = nn.Linear(\n",
        "            in_features = LAT_DIM,\n",
        "            out_features = CAPACITY * 2 * 7 * 7,\n",
        "        )\n",
        "        self.conv2 = nn.ConvTranspose2d(\n",
        "            in_channels = CAPACITY * 2,\n",
        "            out_channels = CAPACITY,\n",
        "            kernel_size = KERN_SIZE,\n",
        "            stride = STRIDE,\n",
        "            padding = PAD,\n",
        "        )\n",
        "        self.conv1 = nn.ConvTranspose2d(\n",
        "            in_channels = CAPACITY,\n",
        "            out_channels = 1,\n",
        "            kernel_size = KERN_SIZE,\n",
        "            stride = STRIDE,\n",
        "            padding = PAD,\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.fc(x)\n",
        "        return torch.sigmoid(self.conv1(\n",
        "                functional.relu(self.conv2(\n",
        "                    x.view(x.size(0), CAPACITY * 2, 7, 7)\n",
        "            ))\n",
        "        ))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PCQPtw5a3DQI"
      },
      "source": [
        "class VariationalAutoencoder(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(VariationalAutoencoder, self).__init__()\n",
        "        \n",
        "        self.encoder = Encoder()\n",
        "        self.decoder = Decoder()\n",
        "\n",
        "    def forward(self, x):\n",
        "        latent_mu, latent_logvar = self.encoder(x)\n",
        "        latent = self.latent_sample(latent_mu, latent_logvar)\n",
        "        x_recon = self.decoder(latent)\n",
        "        return x_recon, latent_mu, latent_logvar\n",
        "\n",
        "    def latent_sample(self, mu, logvar):\n",
        "        if self.training:\n",
        "            # the reparameterization trick\n",
        "            std = logvar.mul(0.5).exp_()\n",
        "            eps = torch.empty_like(std).normal_()\n",
        "            return eps.mul(std).add_(mu)\n",
        "        else:\n",
        "            return mu"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e2CrBYQU4e8r"
      },
      "source": [
        "def reconstruction_erorr(recon_x, x):\n",
        "    return functional.binary_cross_entropy(\n",
        "        recon_x.view(-1, 784),\n",
        "        x.view(-1, 784),\n",
        "        reduction = \"sum\",\n",
        "    )\n",
        "\n",
        "def vae_loss(recon_loss, mu, logvar):\n",
        "    kl_divergence = -0.5 * torch.sum(1 + logvar - mu.pow(2) - logvar.exp())\n",
        "    return recon_loss + VAR_BETA * kl_divergence"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bxImy1XR6FHR"
      },
      "source": [
        "## RRH for Gaussian Mixtures"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2H2L9XvS6Kwj"
      },
      "source": [
        "def mvn_renyi(C, q=1):\n",
        "    \"\"\" Computes the RÃ©nyi heterogeneity for a multivariate Gaussian \n",
        "    Arguments: \n",
        "        C: `ndarray((n,n))`. Covariance matrix\n",
        "        q: `0<float`. Order of the heterogeneity\n",
        "    Returns: \n",
        "        `float`\n",
        "    \"\"\"\n",
        "    n = C.shape[0]\n",
        "    SqrtDetC = np.sqrt(np.linalg.det(C))\n",
        "    if q == 1: \n",
        "        out = (2*np.pi*np.e)**(n/2) * SqrtDetC\n",
        "    elif q == np.inf: \n",
        "        out = (2*np.pi)**(n/2) * SqrtDetC\n",
        "    elif q!=1 and q!=0 and q!=np.inf:\n",
        "        out = ((2*np.pi)**(n/2))*(q**(n/(2*(q-1))))*SqrtDetC\n",
        "    return out"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TkLYVMBu6fDn"
      },
      "source": [
        "def mvn_renyi_alpha(C,  q=1):\n",
        "    \"\"\" Computes the alpha-heterogeneity for a Gaussian mixture where each sample has equal weight\n",
        "\n",
        "    Arguments: \n",
        "\n",
        "        cov: `ndarray((nsamples, n, n))`. Covariance matrices \n",
        "        q: `0<float`. Order of the heterogeneity metric\n",
        "\n",
        "    Returns: \n",
        "\n",
        "        `float`. The alpha-heterogeneity\n",
        "    \"\"\"\n",
        "    K, n, _ = C.shape\n",
        "    p = np.repeat(1/K, K)\n",
        "    if q == 1:\n",
        "        out = np.exp((n + np.sum(p*np.log(np.linalg.det(2*np.pi*C))))/2)\n",
        "    elif q!=np.inf and q!=1 and q!=0:\n",
        "        wbar = (p**q)/np.sum(p**q)\n",
        "        out = ((2*np.pi)**(n/2))*np.sum(wbar*np.sqrt(np.linalg.det(C)))/(q**(n/2))**(1/(1-q))\n",
        "    return out\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4aDzvMEx_X9r"
      },
      "source": [
        "def scale_to_cov(scales):\n",
        "    return np.vstack([np.expand_dims(np.diagflat(s), 0) for s in scales])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DS7dTSHl_e2i"
      },
      "source": [
        "def pool_covariance(means, covs):\n",
        "    K = covs.shape[0] \n",
        "    p = np.repeat(1/K, K)\n",
        "    cov_ = np.einsum('ijk,i->jk', covs, p) + np.einsum('ij,ik,i->jk', means, means, p)\n",
        "    mu_ = np.einsum('ij,i->j', means, p)\n",
        "    return cov_ - np.einsum('i,j->ij', mu_, mu_)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hfwhdEx46mFx"
      },
      "source": [
        "# MNIST Experiments"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qXN-NstR42nu"
      },
      "source": [
        "## Make MNIST training and evaluation sets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R9VbzfzV47ON"
      },
      "source": [
        "img_transform = transforms.Compose([\n",
        "    transforms.ToTensor()\n",
        "])\n",
        "\n",
        "def load_mnist(train):\n",
        "    dataset = MNIST(\n",
        "        root = './data/MNIST',\n",
        "        download = True,\n",
        "        train = train,\n",
        "        transform = img_transform,\n",
        "    )\n",
        "    return DataLoader(dataset, batch_size = BATCH_SIZE, shuffle = True)\n",
        "\n",
        "train_dataloader = load_mnist(train = True)\n",
        "test_dataloader = load_mnist(train = False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0IMlt_q67tJo"
      },
      "source": [
        "# Place into numpy arrays for easier manipulation\n",
        "traindata = list(train_dataloader)\n",
        "traindata = [[sample[0].numpy(), sample[1].numpy()] for sample in traindata]\n",
        "X = np.vstack([sample[0] for sample in traindata])\n",
        "y = np.hstack([sample[1] for sample in traindata])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lvx8i8Ct9yMR"
      },
      "source": [
        "## Load and Evaluate Pre-Trained VAE"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2fw73AnrR4Ej"
      },
      "source": [
        "Load"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vNRYGlvQ5O77",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cc4a7f67-f8fa-42d9-afda-019003d0ee24"
      },
      "source": [
        "pretrained_vae = VariationalAutoencoder()\n",
        "device = torch.device(\"cuda:0\" if GPU and torch.cuda.is_available() else \"cpu\")\n",
        "pretrained_vae = pretrained_vae.to(device)\n",
        "\n",
        "filename = 'vae_2d.pth'\n",
        "\n",
        "if not os.path.isdir('./pretrained'):\n",
        "    os.makedirs('./pretrained')\n",
        "print('downloading ...')\n",
        "urllib.request.urlretrieve(\n",
        "    \"http://geometry.cs.ucl.ac.uk/creativeai/pretrained/\" + filename,\n",
        "    \"./pretrained/\" + filename,\n",
        ")\n",
        "pretrained_vae.load_state_dict(torch.load('./pretrained/' + filename))\n",
        "print('done')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "downloading ...\n",
            "done\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1yMsC2YNR8kq"
      },
      "source": [
        "Evaluate"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nRS4NG0mJJZY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d78b200f-5b2c-4ecc-e560-fff8acb75062"
      },
      "source": [
        "# set to evaluation mode\n",
        "pretrained_vae.eval()\n",
        "\n",
        "test_loss_avg, recon_loss_avg, num_batches = 0, 0, 0\n",
        "for image_batch, _ in test_dataloader:\n",
        "    \n",
        "    with torch.no_grad():\n",
        "    \n",
        "        image_batch = image_batch.to(device)\n",
        "\n",
        "        # vae reconstruction\n",
        "        image_batch_recon, latent_mu, latent_logvar = pretrained_vae(image_batch)\n",
        "\n",
        "        # reconstruction error\n",
        "        recon_loss = reconstruction_erorr(image_batch_recon, image_batch)\n",
        "        loss = vae_loss(recon_loss, latent_mu, latent_logvar)\n",
        "\n",
        "        recon_loss_avg += recon_loss\n",
        "        test_loss_avg += loss.item()\n",
        "        num_batches += 1\n",
        "    \n",
        "recon_loss_avg /= num_batches\n",
        "test_loss_avg /= num_batches\n",
        "print('average reconstruction error: %f' % (recon_loss_avg))\n",
        "print('average error: %f' % (test_loss_avg))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "average reconstruction error: 18493.664062\n",
            "average error: 19294.807194\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N7XQuBW63DmN"
      },
      "source": [
        "## Train and Evaluate VAE"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lb5IpN6M3KKk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e702d321-1bca-4e55-b43d-61cd4777abaa"
      },
      "source": [
        "vae = VariationalAutoencoder()\n",
        "device = torch.device(\"cuda:0\" if GPU and torch.cuda.is_available() else \"cpu\")\n",
        "vae = vae.to(device)\n",
        "\n",
        "num_params = sum(p.numel() for p in vae.parameters() if p.requires_grad)\n",
        "print('Number of parameters: %d' % num_params)\n",
        "\n",
        "optimizer = torch.optim.Adam(\n",
        "    params = vae.parameters(),\n",
        "    lr = LRN_RATE,\n",
        "    weight_decay = 1e-5,\n",
        ")\n",
        "\n",
        "# set to training mode\n",
        "vae.train()\n",
        "\n",
        "train_loss_avg = []\n",
        "\n",
        "print('Training ...')\n",
        "for epoch in range(EPOCH_NUM):\n",
        "    train_loss_avg.append(0)\n",
        "    num_batches = 0\n",
        "    \n",
        "    for image_batch, _ in train_dataloader:\n",
        "        \n",
        "        image_batch = image_batch.to(device)\n",
        "\n",
        "        # vae reconstruction\n",
        "        image_batch_recon, latent_mu, latent_logvar = vae(image_batch)\n",
        "        \n",
        "        # reconstruction error\n",
        "        recon_loss = reconstruction_erorr(image_batch_recon, image_batch)\n",
        "        loss = vae_loss(recon_loss, latent_mu, latent_logvar)\n",
        "        \n",
        "        # backpropagation\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        \n",
        "        # one step of the optmizer (using the gradients from backpropagation)\n",
        "        optimizer.step()\n",
        "        \n",
        "        train_loss_avg[-1] += loss.item()\n",
        "        num_batches += 1\n",
        "        \n",
        "    train_loss_avg[-1] /= num_batches\n",
        "    print('Epoch [%d / %d] average reconstruction error: %f' % (epoch+1, EPOCH_NUM, train_loss_avg[-1]))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of parameters: 308357\n",
            "Training ...\n",
            "Epoch [1 / 50] average reconstruction error: 24048.731531\n",
            "Epoch [2 / 50] average reconstruction error: 21667.731683\n",
            "Epoch [3 / 50] average reconstruction error: 21049.359298\n",
            "Epoch [4 / 50] average reconstruction error: 20652.804427\n",
            "Epoch [5 / 50] average reconstruction error: 20374.810378\n",
            "Epoch [6 / 50] average reconstruction error: 20175.633152\n",
            "Epoch [7 / 50] average reconstruction error: 20017.137179\n",
            "Epoch [8 / 50] average reconstruction error: 19916.152313\n",
            "Epoch [9 / 50] average reconstruction error: 19817.292373\n",
            "Epoch [10 / 50] average reconstruction error: 19746.652104\n",
            "Epoch [11 / 50] average reconstruction error: 19674.891341\n",
            "Epoch [12 / 50] average reconstruction error: 19610.826786\n",
            "Epoch [13 / 50] average reconstruction error: 19559.579778\n",
            "Epoch [14 / 50] average reconstruction error: 19513.977491\n",
            "Epoch [15 / 50] average reconstruction error: 19456.698226\n",
            "Epoch [16 / 50] average reconstruction error: 19425.032179\n",
            "Epoch [17 / 50] average reconstruction error: 19392.179294\n",
            "Epoch [18 / 50] average reconstruction error: 19336.783934\n",
            "Epoch [19 / 50] average reconstruction error: 19314.401009\n",
            "Epoch [20 / 50] average reconstruction error: 19268.584794\n",
            "Epoch [21 / 50] average reconstruction error: 19247.323432\n",
            "Epoch [22 / 50] average reconstruction error: 19211.102285\n",
            "Epoch [23 / 50] average reconstruction error: 19176.955971\n",
            "Epoch [24 / 50] average reconstruction error: 19149.472408\n",
            "Epoch [25 / 50] average reconstruction error: 19129.520991\n",
            "Epoch [26 / 50] average reconstruction error: 19106.242171\n",
            "Epoch [27 / 50] average reconstruction error: 19089.073255\n",
            "Epoch [28 / 50] average reconstruction error: 19049.692173\n",
            "Epoch [29 / 50] average reconstruction error: 19027.595855\n",
            "Epoch [30 / 50] average reconstruction error: 19006.808821\n",
            "Epoch [31 / 50] average reconstruction error: 18993.003394\n",
            "Epoch [32 / 50] average reconstruction error: 18966.829237\n",
            "Epoch [33 / 50] average reconstruction error: 18956.386865\n",
            "Epoch [34 / 50] average reconstruction error: 18929.104430\n",
            "Epoch [35 / 50] average reconstruction error: 18922.696708\n",
            "Epoch [36 / 50] average reconstruction error: 18900.906768\n",
            "Epoch [37 / 50] average reconstruction error: 18885.078993\n",
            "Epoch [38 / 50] average reconstruction error: 18865.924773\n",
            "Epoch [39 / 50] average reconstruction error: 18854.496666\n",
            "Epoch [40 / 50] average reconstruction error: 18838.703608\n",
            "Epoch [41 / 50] average reconstruction error: 18830.748586\n",
            "Epoch [42 / 50] average reconstruction error: 18811.109696\n",
            "Epoch [43 / 50] average reconstruction error: 18790.299821\n",
            "Epoch [44 / 50] average reconstruction error: 18778.377417\n",
            "Epoch [45 / 50] average reconstruction error: 18767.953042\n",
            "Epoch [46 / 50] average reconstruction error: 18766.228459\n",
            "Epoch [47 / 50] average reconstruction error: 18747.496770\n",
            "Epoch [48 / 50] average reconstruction error: 18734.762804\n",
            "Epoch [49 / 50] average reconstruction error: 18717.858952\n",
            "Epoch [50 / 50] average reconstruction error: 18715.020995\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2FVd05s4I4YM"
      },
      "source": [
        "plt.ion()\n",
        "\n",
        "fig = plt.figure()\n",
        "plt.plot(train_loss_avg)\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "isT5TzCPJEE1"
      },
      "source": [
        "# set to evaluation mode\n",
        "vae.eval()\n",
        "\n",
        "test_loss_avg, num_batches = 0, 0\n",
        "for image_batch, _ in test_dataloader:\n",
        "    \n",
        "    with torch.no_grad():\n",
        "    \n",
        "        image_batch = image_batch.to(device)\n",
        "\n",
        "        # vae reconstruction\n",
        "        image_batch_recon, latent_mu, latent_logvar = vae(image_batch)\n",
        "\n",
        "        # reconstruction error\n",
        "        loss = vae_loss(image_batch_recon, image_batch, latent_mu, latent_logvar)\n",
        "\n",
        "        test_loss_avg += loss.item()\n",
        "        num_batches += 1\n",
        "    \n",
        "test_loss_avg /= num_batches\n",
        "print('average reconstruction error: %f' % (test_loss_avg))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RG67lA7u6pAY"
      },
      "source": [
        "## Experiment 1: $\\beta$ heterogeneity of each digit class"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "btJuQ-U3QuuO"
      },
      "source": [
        "### 1.1 RRH on MNIST-trained VAE"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IinU-xeM6fg_"
      },
      "source": [
        "gammas = []\n",
        "alphas = []\n",
        "betas = []\n",
        "for i in range(10):\n",
        "    mu, logvar = vae.encoder(torch.Tensor(X[y == i]).to(device))\n",
        "    loc = mu.cpu().detach().numpy()\n",
        "    scale = logvar.exp().cpu().detach().numpy()\n",
        "    cov = scale_to_cov(scale)\n",
        "    cov = scale_to_cov(scale)\n",
        "    gamma = mvn_renyi(pool_covariance(loc, cov), q=1)\n",
        "    alpha = mvn_renyi_alpha(cov,q=1)\n",
        "    beta = gamma/alpha\n",
        "    gammas.append(gamma)\n",
        "    alphas.append(alpha)\n",
        "    betas.append(beta)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dwMAcQBaBDCM"
      },
      "source": [
        "hetvalues = [gammas, alphas, betas]\n",
        "plotlabels = [r\"Pooled\", r\"Within-Observation\", r\"Between-Observation\"]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xcRWRha365r-"
      },
      "source": [
        "fig, ax = plt.subplots(ncols=3, figsize=(9, 2.5))\n",
        "ax[0].set_ylabel(\"Heterogeneity\")\n",
        "\n",
        "for i in range(3): \n",
        "    ax[i].set_title(plotlabels[i])\n",
        "    ax[i].set_xlabel(\"Digit\")\n",
        "    ax[i].set_xticks(np.arange(10))\n",
        "    ax[i].set_xticklabels(np.arange(10))\n",
        "    ax[i].bar(\n",
        "        np.arange(10),\n",
        "        hetvalues[i],\n",
        "        facecolor = plt.get_cmap(\"Greys\")(0.4), \n",
        "        edgecolor = \"black\",\n",
        "    )\n",
        "plt.tight_layout()\n",
        "plt.savefig(\"digit-class-heterogeneity.pdf\", bbox_inches=\"tight\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y0rEBIdMQ1lS"
      },
      "source": [
        "### 1.2 RRH on Pre-trained VAE"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mDgSUDakBqPj"
      },
      "source": [
        "gammas = []\n",
        "alphas = []\n",
        "betas = []\n",
        "for i in range(10):\n",
        "    mu, logvar = pretrained_vae.encoder(torch.Tensor(X[y == i]).to(device))\n",
        "    loc = mu.cpu().detach().numpy()\n",
        "    scale = logvar.exp().cpu().detach().numpy()\n",
        "    cov = scale_to_cov(scale)\n",
        "    cov = scale_to_cov(scale)\n",
        "    gamma = mvn_renyi(pool_covariance(loc, cov), q=1)\n",
        "    alpha = mvn_renyi_alpha(cov,q=1)\n",
        "    beta = gamma/alpha\n",
        "    gammas.append(gamma)\n",
        "    alphas.append(alpha)\n",
        "    betas.append(beta)\n",
        "\n",
        "hetvalues = [gammas, alphas, betas]\n",
        "plotlabels = [r\"Pooled\", r\"Within-Observation\", r\"Between-Observation\"]\n",
        "\n",
        "fig, ax = plt.subplots(ncols=3, figsize=(9, 2.5))\n",
        "ax[0].set_ylabel(\"Heterogeneity\")\n",
        "\n",
        "for i in range(3): \n",
        "    ax[i].set_title(plotlabels[i])\n",
        "    ax[i].set_xlabel(\"Digit\")\n",
        "    ax[i].set_xticks(np.arange(10))\n",
        "    ax[i].set_xticklabels(np.arange(10))\n",
        "    ax[i].bar(\n",
        "        np.arange(10),\n",
        "        hetvalues[i],\n",
        "        facecolor = plt.get_cmap(\"Greys\")(0.4), \n",
        "        edgecolor = \"black\",\n",
        "    )\n",
        "plt.tight_layout()\n",
        "plt.savefig(\"digit-class-heterogeneity.pdf\", bbox_inches=\"tight\")"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}