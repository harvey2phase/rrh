{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "RRH_MNIST.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "kAg4fEcS9156",
        "bxImy1XR6FHR",
        "qXN-NstR42nu"
      ],
      "authorship_tag": "ABX9TyNT2OOMofHNe2sGxCdKMx7x"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "nlBt0FWz8iXu"
      },
      "source": [
        "import os\n",
        "import urllib\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as functional\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision.datasets import MNIST"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cuXs60E66A8k"
      },
      "source": [
        "# Definitions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DoZjwrH3xpei"
      },
      "source": [
        "LAT_DIM = 2\n",
        "EPOCH_NUM = 25\n",
        "BATCH_SIZE = 128\n",
        "CAPACITY = 64\n",
        "LRN_RATE = 1e-3\n",
        "VAR_BETA = 1\n",
        "\n",
        "KERN_SIZE = 4\n",
        "STRIDE = 2\n",
        "PAD = 1\n",
        "\n",
        "GPU = True"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kAg4fEcS9156"
      },
      "source": [
        "## VAE"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UkcWN5LXyCEo"
      },
      "source": [
        "class Encoder(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Encoder, self).__init__()\n",
        "        \n",
        "        # CAPACITY * 14 * 14\n",
        "        self.conv1 = nn.Conv2d(\n",
        "            in_channels = 1,\n",
        "            out_channels = CAPACITY,\n",
        "            kernel_size = KERN_SIZE,\n",
        "            stride = STRIDE,\n",
        "            padding = PAD,\n",
        "        )\n",
        "        # CAPACITY * 7 * 7\n",
        "        self.conv2 = nn.Conv2d(\n",
        "            in_channels = CAPACITY,\n",
        "            out_channels = CAPACITY * 2,\n",
        "            kernel_size = KERN_SIZE,\n",
        "            stride = STRIDE,\n",
        "            padding = PAD,\n",
        "        )\n",
        "        self.fc_mu = nn.Linear(\n",
        "            in_features = CAPACITY * 2 * 7 * 7,\n",
        "            out_features = LAT_DIM,\n",
        "        )\n",
        "        self.fc_logvar = nn.Linear(\n",
        "            in_features = CAPACITY * 2 * 7 * 7,\n",
        "            out_features = LAT_DIM,\n",
        "        )\n",
        "        \n",
        "    def forward(self, x):\n",
        "        x = functional.relu(self.conv2(\n",
        "            functional.relu(self.conv1(x))\n",
        "        ))\n",
        "        x = x.view(x.size(0), -1)\n",
        "        x_mu = self.fc_mu(x)\n",
        "        x_logvar = self.fc_logvar(x)\n",
        "        return x_mu, x_logvar"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "35jQ8f41zRFg"
      },
      "source": [
        "class Decoder(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Decoder, self).__init__()\n",
        "        \n",
        "        self.fc = nn.Linear(\n",
        "            in_features = LAT_DIM,\n",
        "            out_features = CAPACITY * 2 * 7 * 7,\n",
        "        )\n",
        "        self.conv2 = nn.ConvTranspose2d(\n",
        "            in_channels = CAPACITY * 2,\n",
        "            out_channels = CAPACITY,\n",
        "            kernel_size = KERN_SIZE,\n",
        "            stride = STRIDE,\n",
        "            padding = PAD,\n",
        "        )\n",
        "        self.conv1 = nn.ConvTranspose2d(\n",
        "            in_channels = CAPACITY,\n",
        "            out_channels = 1,\n",
        "            kernel_size = KERN_SIZE,\n",
        "            stride = STRIDE,\n",
        "            padding = PAD,\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.fc(x)\n",
        "        return torch.sigmoid(self.conv1(\n",
        "                functional.relu(self.conv2(\n",
        "                    x.view(x.size(0), CAPACITY * 2, 7, 7)\n",
        "            ))\n",
        "        ))"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PCQPtw5a3DQI"
      },
      "source": [
        "class VariationalAutoencoder(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(VariationalAutoencoder, self).__init__()\n",
        "        \n",
        "        self.encoder = Encoder()\n",
        "        self.decoder = Decoder()\n",
        "\n",
        "    def forward(self, x):\n",
        "        latent_mu, latent_logvar = self.encoder(x)\n",
        "        latent = self.latent_sample(latent_mu, latent_logvar)\n",
        "        x_recon = self.decoder(latent)\n",
        "        return x_recon, latent_mu, latent_logvar\n",
        "\n",
        "    def latent_sample(self, mu, logvar):\n",
        "        if self.training:\n",
        "            # the reparameterization trick\n",
        "            std = logvar.mul(0.5).exp_()\n",
        "            eps = torch.empty_like(std).normal_()\n",
        "            return eps.mul(std).add_(mu)\n",
        "        else:\n",
        "            return mu"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e2CrBYQU4e8r"
      },
      "source": [
        "def reconstruction_erorr(recon_x, x):\n",
        "    return functional.binary_cross_entropy(\n",
        "        recon_x.view(-1, 784),\n",
        "        x.view(-1, 784),\n",
        "        reduction = \"sum\",\n",
        "    )\n",
        "\n",
        "def vae_loss(recon_loss, mu, logvar):\n",
        "    kl_divergence = -0.5 * torch.sum(1 + logvar - mu.pow(2) - logvar.exp())\n",
        "    return recon_loss + VAR_BETA * kl_divergence"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bxImy1XR6FHR"
      },
      "source": [
        "## RRH for Gaussian Mixtures"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2H2L9XvS6Kwj"
      },
      "source": [
        "def mvn_renyi(C, q=1):\n",
        "    \"\"\" Computes the RÃ©nyi heterogeneity for a multivariate Gaussian \n",
        "    Arguments: \n",
        "        C: `ndarray((n,n))`. Covariance matrix\n",
        "        q: `0<float`. Order of the heterogeneity\n",
        "    Returns: \n",
        "        `float`\n",
        "    \"\"\"\n",
        "    n = C.shape[0]\n",
        "    SqrtDetC = np.sqrt(np.linalg.det(C))\n",
        "    if q == 1: \n",
        "        out = (2*np.pi*np.e)**(n/2) * SqrtDetC\n",
        "    elif q == np.inf: \n",
        "        out = (2*np.pi)**(n/2) * SqrtDetC\n",
        "    elif q!=1 and q!=0 and q!=np.inf:\n",
        "        out = ((2*np.pi)**(n/2))*(q**(n/(2*(q-1))))*SqrtDetC\n",
        "    return out"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TkLYVMBu6fDn"
      },
      "source": [
        "def mvn_renyi_alpha(C,  q=1):\n",
        "    \"\"\" Computes the alpha-heterogeneity for a Gaussian mixture where each sample has equal weight\n",
        "\n",
        "    Arguments: \n",
        "\n",
        "        cov: `ndarray((nsamples, n, n))`. Covariance matrices \n",
        "        q: `0<float`. Order of the heterogeneity metric\n",
        "\n",
        "    Returns: \n",
        "\n",
        "        `float`. The alpha-heterogeneity\n",
        "    \"\"\"\n",
        "    K, n, _ = C.shape\n",
        "    p = np.repeat(1/K, K)\n",
        "    if q == 1:\n",
        "        out = np.exp((n + np.sum(p*np.log(np.linalg.det(2*np.pi*C))))/2)\n",
        "    elif q!=np.inf and q!=1 and q!=0:\n",
        "        wbar = (p**q)/np.sum(p**q)\n",
        "        out = ((2*np.pi)**(n/2))*np.sum(wbar*np.sqrt(np.linalg.det(C)))/(q**(n/2))**(1/(1-q))\n",
        "    return out\n"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4aDzvMEx_X9r"
      },
      "source": [
        "def scale_to_cov(scales):\n",
        "    return np.vstack([np.expand_dims(np.diagflat(s), 0) for s in scales])"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DS7dTSHl_e2i"
      },
      "source": [
        "def pool_covariance(means, covs):\n",
        "    K = covs.shape[0] \n",
        "    p = np.repeat(1/K, K)\n",
        "    cov_ = np.einsum('ijk,i->jk', covs, p) + np.einsum('ij,ik,i->jk', means, means, p)\n",
        "    mu_ = np.einsum('ij,i->j', means, p)\n",
        "    return cov_ - np.einsum('i,j->ij', mu_, mu_)"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N7XQuBW63DmN"
      },
      "source": [
        "## VAE Training and Evaluation\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TFpBblS_eLg1"
      },
      "source": [
        "device = torch.device(\"cuda:0\" if GPU and torch.cuda.is_available() else \"cpu\")"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lb5IpN6M3KKk"
      },
      "source": [
        "def train_one_model(evaluate = False):\n",
        "\n",
        "    vae = VariationalAutoencoder()\n",
        "    vae = vae.to(device)\n",
        "    \n",
        "    num_params = sum(p.numel() for p in vae.parameters() if p.requires_grad)\n",
        "    print('Number of parameters: %d' % num_params)\n",
        "    \n",
        "    optimizer = torch.optim.Adam(\n",
        "        params = vae.parameters(),\n",
        "        lr = LRN_RATE,\n",
        "        weight_decay = 1e-5,\n",
        "    )\n",
        "    \n",
        "    # set to training mode\n",
        "    vae.train()\n",
        "    \n",
        "    train_recon_loss_avg, train_loss_avg = [], []\n",
        "    test_recon_loss_avg, test_loss_avg = [], []\n",
        "    \n",
        "    print(\"Training: \", end = \"\")\n",
        "    for epoch in range(EPOCH_NUM):\n",
        "        train_recon_loss_avg.append(0)\n",
        "        train_loss_avg.append(0)\n",
        "        num_batches = 0\n",
        "        \n",
        "        for image_batch, _ in train_dataloader:\n",
        "            \n",
        "            image_batch = image_batch.to(device)\n",
        "    \n",
        "            # vae reconstruction\n",
        "            image_batch_recon, latent_mu, latent_logvar = vae(image_batch)\n",
        "            \n",
        "            # reconstruction error\n",
        "            recon_loss = reconstruction_erorr(image_batch_recon, image_batch)\n",
        "            loss = vae_loss(recon_loss, latent_mu, latent_logvar)\n",
        "            \n",
        "            # backpropagation\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            \n",
        "            # one step of the optmizer (using the gradients from backpropagation)\n",
        "            optimizer.step()\n",
        "            \n",
        "            train_recon_loss_avg[-1] += recon_loss\n",
        "            train_loss_avg[-1] += loss.item()\n",
        "            num_batches += 1\n",
        "            \n",
        "        train_recon_loss_avg[-1] /= num_batches\n",
        "        train_loss_avg[-1] /= num_batches\n",
        "\n",
        "        if evaluate:\n",
        "            recon_loss_avg, loss_avg = eval_model(vae)\n",
        "            test_recon_loss_avg.append(recon_loss_avg)\n",
        "            test_loss_avg.append(loss_avg)\n",
        "            vae.train()\n",
        "        \n",
        "        print(\"%d, \" % (epoch+1), end = \"\")\n",
        "        \n",
        "    if not evaluate:\n",
        "        test_recon_loss_avg, test_loss_avg = None, None\n",
        "    print()\n",
        "    return vae, train_recon_loss_avg, train_loss_avg, test_recon_loss_avg, test_loss_avg"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2FVd05s4I4YM"
      },
      "source": [
        "def plot_loss(train_loss_avg, eval_loss_avg, i = 0, y = \"Loss\"):\n",
        "    plt.ion()\n",
        "\n",
        "    fig = plt.figure(i)\n",
        "    plt.plot(train_loss_avg, c = \"blue\", label = \"training\")\n",
        "    plt.plot(eval_loss_avg, c = \"red\", label = \"evaluation\")\n",
        "    plt.xlabel('Epochs')\n",
        "    plt.ylabel(y)\n",
        "    plt.legend()\n",
        "    plt.show()"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "isT5TzCPJEE1"
      },
      "source": [
        "def eval_model(vae):\n",
        "    vae.eval()\n",
        "    \n",
        "    test_loss_avg, test_recon_loss_avg, num_batches = 0, 0, 0\n",
        "    for image_batch, _ in test_dataloader:\n",
        "        \n",
        "        with torch.no_grad():\n",
        "        \n",
        "            image_batch = image_batch.to(device)\n",
        "    \n",
        "            # vae reconstruction\n",
        "            image_batch_recon, latent_mu, latent_logvar = vae(image_batch)\n",
        "    \n",
        "            # reconstruction error\n",
        "            recon_loss = reconstruction_erorr(image_batch_recon, image_batch)\n",
        "            loss = vae_loss(recon_loss, latent_mu, latent_logvar)\n",
        "    \n",
        "            test_recon_loss_avg += recon_loss\n",
        "            test_loss_avg += loss.item()\n",
        "            num_batches += 1\n",
        "        \n",
        "    test_recon_loss_avg /= num_batches\n",
        "    test_loss_avg /= num_batches\n",
        "\n",
        "    return test_recon_loss_avg, test_loss_avg\n",
        "    #print('average reconstruction error: %f' % (test_recon_loss_avg))\n",
        "    #print('average error: %f' % (test_loss_avg))"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vNRYGlvQ5O77"
      },
      "source": [
        "def load_pretrained_vae():\n",
        "    pretrained_vae = VariationalAutoencoder()\n",
        "    pretrained_vae = pretrained_vae.to(device)\n",
        "    \n",
        "    filename = 'vae_2d.pth'\n",
        "    \n",
        "    if not os.path.isdir('./pretrained'):\n",
        "        os.makedirs('./pretrained')\n",
        "    urllib.request.urlretrieve(\n",
        "        \"http://geometry.cs.ucl.ac.uk/creativeai/pretrained/\" + filename,\n",
        "        \"./pretrained/\" + filename,\n",
        "    )\n",
        "    pretrained_vae.load_state_dict(torch.load('./pretrained/' + filename))\n",
        "    return pretrained_vae"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RG67lA7u6pAY"
      },
      "source": [
        "## Compute and plot RRH for VAE"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IinU-xeM6fg_"
      },
      "source": [
        "def calculate_rrh(vae):\n",
        "    gammas = []\n",
        "    alphas = []\n",
        "    betas = []\n",
        "    for i in range(10):\n",
        "        mu, logvar = vae.encoder(torch.Tensor(X[y == i]).to(device))\n",
        "        loc = mu.cpu().detach().numpy()\n",
        "        scale = logvar.exp().cpu().detach().numpy()\n",
        "        cov = scale_to_cov(scale)\n",
        "        cov = scale_to_cov(scale)\n",
        "        gamma = mvn_renyi(pool_covariance(loc, cov), q=1)\n",
        "        alpha = mvn_renyi_alpha(cov,q=1)\n",
        "        beta = gamma/alpha\n",
        "        gammas.append(gamma)\n",
        "        alphas.append(alpha)\n",
        "        betas.append(beta)\n",
        "    return np.array(gammas), np.array(alphas), np.array(betas)"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xcRWRha365r-"
      },
      "source": [
        "def plot_rrh(gammas, alphas, betas, sigmas = None):\n",
        "    if not (len(gammas) == len(alphas) or len(gammas) == len(betas)):\n",
        "        sys.exit(\"Mismatched matrix size\")\n",
        "    n = len(gammas)\n",
        "    hetvalues = [gammas, alphas, betas]\n",
        "    plotlabels = [r\"Pooled\", r\"Within-Observation\", r\"Between-Observation\"]\n",
        "    \n",
        "    fig, ax = plt.subplots(ncols=3, figsize=(9, 2.5))\n",
        "    ax[0].set_ylabel(\"Heterogeneity\")\n",
        "    \n",
        "    for i in range(3): \n",
        "        ax[i].set_title(plotlabels[i])\n",
        "        ax[i].set_xlabel(\"Digit\")\n",
        "        ax[i].set_xticks(np.arange(10))\n",
        "        ax[i].set_xticklabels(np.arange(10))\n",
        "        ax[i].bar(\n",
        "            np.arange(10),\n",
        "            hetvalues[i],\n",
        "            facecolor = plt.get_cmap(\"Greys\")(0.4), \n",
        "            edgecolor = \"black\",\n",
        "        )\n",
        "        if not sigmas == None:\n",
        "            ax[i].errorbar(\n",
        "                np.arange(10),\n",
        "                hetvalues[i],\n",
        "                yerr = sigmas[i],\n",
        "                fmt = \"none\",\n",
        "                ecolor = \"r\",\n",
        "                capsize = 3,\n",
        "                label = \"std deviation\",\n",
        "            )\n",
        "            ax[i].errorbar(\n",
        "                np.arange(10),\n",
        "                hetvalues[i],\n",
        "                yerr = sigmas[i] / np.sqrt(n),\n",
        "                fmt = \"none\",\n",
        "                ecolor = \"b\",\n",
        "                capsize = 3,\n",
        "                label = \"std error\",\n",
        "            )\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(\"digit-class-heterogeneity.pdf\", bbox_inches=\"tight\")"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hfwhdEx46mFx"
      },
      "source": [
        "# MNIST Experiments"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qXN-NstR42nu"
      },
      "source": [
        "## Make MNIST training and evaluation sets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R9VbzfzV47ON"
      },
      "source": [
        "img_transform = transforms.Compose([\n",
        "    transforms.ToTensor()\n",
        "])\n",
        "\n",
        "def load_mnist(train):\n",
        "    dataset = MNIST(\n",
        "        root = './data/MNIST',\n",
        "        download = True,\n",
        "        train = train,\n",
        "        transform = img_transform,\n",
        "    )\n",
        "    return DataLoader(dataset, batch_size = BATCH_SIZE, shuffle = True)\n",
        "\n",
        "train_dataloader = load_mnist(train = True)\n",
        "test_dataloader = load_mnist(train = False)"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0IMlt_q67tJo"
      },
      "source": [
        "# Place into numpy arrays for easier manipulation\n",
        "traindata = list(train_dataloader)\n",
        "traindata = [[sample[0].numpy(), sample[1].numpy()] for sample in traindata]\n",
        "X = np.vstack([sample[0] for sample in traindata])\n",
        "y = np.hstack([sample[1] for sample in traindata])"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eM3hF-q0VipP"
      },
      "source": [
        "# Experiments"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mOOtu98Jv1-_"
      },
      "source": [
        "def het_sigma(matrix, avg = None):\n",
        "    if avg == None:\n",
        "        avg = het_avg(matrix)\n",
        "    n = len(matrix)\n",
        "    mse = (matrix[0] - avg) ** 2\n",
        "    for i in range(1, n):\n",
        "        mse += (matrix[i] - avg) ** 2\n",
        "    return np.sqrt(mse / n)\n",
        "\n",
        "def het_sum(matrix):\n",
        "    sum = matrix[0] + matrix[1]\n",
        "    for i in range(2, len(matrix)):\n",
        "        sum += matrix[i]\n",
        "    return sum\n",
        "\n",
        "def het_avg(matrix):\n",
        "    return het_sum(matrix) / len(matrix)"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "idP_RI6bBttt"
      },
      "source": [
        "# matrix[i] is the heterogeneity array for vae_i\n",
        "# matrix[i][j] is the heterogeneity for digit_j for vae_i\n",
        "\n",
        "def test_models(n, gamma_matrix, alpha_matrix, beta_matrix):\n",
        "    for _ in range(n):\n",
        "        vae, train_recon_loss_avg, train_loss_avg, test_recon_loss_avg, test_loss_avg = train_one_model()\n",
        "    \n",
        "        plot_loss(train_loss_avg, eval_loss_avg)\n",
        "        plot_loss(train_recon_loss_avg, eval_recon_loss_avg, y = \"Reconstruction Error\")\n",
        "    \n",
        "        gammas, alphas, betas = calculate_rrh(vae)\n",
        "        gamma_matrix.append(gammas)\n",
        "        alpha_matrix.append(alphas)\n",
        "        beta_matrix.append(betas)\n",
        "    return gamma_matrix, alpha_matrix, beta_matrix\n",
        "\n",
        "def plot_rrh_matrices(gamma_matrix, alpha_matrix, beta_matrix):\n",
        "    gamma_avg = het_avg(gamma_matrix)\n",
        "    alpha_avg = het_avg(alpha_matrix)\n",
        "    beta_avg = het_avg(beta_matrix)\n",
        "    \n",
        "    gamma_sigma = het_sigma(gamma_matrix)\n",
        "    alpha_sigma = het_sigma(alpha_matrix)\n",
        "    beta_sigma = het_sigma(beta_matrix)\n",
        "    \n",
        "    plot_rrh(gamma_avg, alpha_avg, beta_avg, sigmas = [gamma_sigma, alpha_sigma, beta_sigma])"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bzmQvee5qsLp",
        "outputId": "dad1ec3d-9115-480f-c1a2-c83268a49600"
      },
      "source": [
        "N = 3\n",
        "for _ in range(N):\n",
        "    n = 5\n",
        "    gamma_matrix, alpha_matrix, beta_matrix = test_models(n, [], [], [])\n",
        "    plot_rrh_matrices(gamma_matrix, alpha_matrix, beta_matrix)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of parameters: 308357\n",
            "Training: 1, 2, 3, 4, 5, "
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lvx8i8Ct9yMR"
      },
      "source": [
        "## Load, Evaluate, and Plot RRH for Pre-Trained VAE"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nRS4NG0mJJZY"
      },
      "source": [
        "pretrained_vae = load_pretrained_vae()\n",
        "eval_model(pretrained_vae)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_nN1Kftyh42Z"
      },
      "source": [
        "gammas, alphas, betas = calculate_rrh(pretrained_vae)\n",
        "plot_rrh(gammas, alphas, betas)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}