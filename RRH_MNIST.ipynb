{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "RRH_MNIST.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "kAg4fEcS9156",
        "bxImy1XR6FHR",
        "qXN-NstR42nu"
      ],
      "authorship_tag": "ABX9TyNItoThiJCUGUBDaA4aM80W",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/harvey2phase/rrh/blob/main/RRH_MNIST.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nlBt0FWz8iXu"
      },
      "source": [
        "import os\n",
        "import urllib\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as functional\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision.datasets import MNIST"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cuXs60E66A8k"
      },
      "source": [
        "# Definitions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DoZjwrH3xpei"
      },
      "source": [
        "LAT_DIM = 2\n",
        "EPOCH_NUM = 35\n",
        "BATCH_SIZE = 128\n",
        "CAPACITY = 64\n",
        "LRN_RATE = 1e-3\n",
        "VAR_BETA = 1\n",
        "\n",
        "KERN_SIZE = 4\n",
        "STRIDE = 2\n",
        "PAD = 1\n",
        "\n",
        "GPU = True"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kAg4fEcS9156"
      },
      "source": [
        "## VAE"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UkcWN5LXyCEo"
      },
      "source": [
        "class Encoder(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Encoder, self).__init__()\n",
        "        \n",
        "        # CAPACITY * 14 * 14\n",
        "        self.conv1 = nn.Conv2d(\n",
        "            in_channels = 1,\n",
        "            out_channels = CAPACITY,\n",
        "            kernel_size = KERN_SIZE,\n",
        "            stride = STRIDE,\n",
        "            padding = PAD,\n",
        "        )\n",
        "        # CAPACITY * 7 * 7\n",
        "        self.conv2 = nn.Conv2d(\n",
        "            in_channels = CAPACITY,\n",
        "            out_channels = CAPACITY * 2,\n",
        "            kernel_size = KERN_SIZE,\n",
        "            stride = STRIDE,\n",
        "            padding = PAD,\n",
        "        )\n",
        "        self.fc_mu = nn.Linear(\n",
        "            in_features = CAPACITY * 2 * 7 * 7,\n",
        "            out_features = LAT_DIM,\n",
        "        )\n",
        "        self.fc_logvar = nn.Linear(\n",
        "            in_features = CAPACITY * 2 * 7 * 7,\n",
        "            out_features = LAT_DIM,\n",
        "        )\n",
        "        \n",
        "    def forward(self, x):\n",
        "        x = functional.relu(self.conv2(\n",
        "            functional.relu(self.conv1(x))\n",
        "        ))\n",
        "        x = x.view(x.size(0), -1)\n",
        "        x_mu = self.fc_mu(x)\n",
        "        x_logvar = self.fc_logvar(x)\n",
        "        return x_mu, x_logvar"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "35jQ8f41zRFg"
      },
      "source": [
        "class Decoder(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Decoder, self).__init__()\n",
        "        \n",
        "        self.fc = nn.Linear(\n",
        "            in_features = LAT_DIM,\n",
        "            out_features = CAPACITY * 2 * 7 * 7,\n",
        "        )\n",
        "        self.conv2 = nn.ConvTranspose2d(\n",
        "            in_channels = CAPACITY * 2,\n",
        "            out_channels = CAPACITY,\n",
        "            kernel_size = KERN_SIZE,\n",
        "            stride = STRIDE,\n",
        "            padding = PAD,\n",
        "        )\n",
        "        self.conv1 = nn.ConvTranspose2d(\n",
        "            in_channels = CAPACITY,\n",
        "            out_channels = 1,\n",
        "            kernel_size = KERN_SIZE,\n",
        "            stride = STRIDE,\n",
        "            padding = PAD,\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.fc(x)\n",
        "        return torch.sigmoid(self.conv1(\n",
        "                functional.relu(self.conv2(\n",
        "                    x.view(x.size(0), CAPACITY * 2, 7, 7)\n",
        "            ))\n",
        "        ))"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PCQPtw5a3DQI"
      },
      "source": [
        "class VariationalAutoencoder(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(VariationalAutoencoder, self).__init__()\n",
        "        \n",
        "        self.encoder = Encoder()\n",
        "        self.decoder = Decoder()\n",
        "\n",
        "    def forward(self, x):\n",
        "        latent_mu, latent_logvar = self.encoder(x)\n",
        "        latent = self.latent_sample(latent_mu, latent_logvar)\n",
        "        x_recon = self.decoder(latent)\n",
        "        return x_recon, latent_mu, latent_logvar\n",
        "\n",
        "    def latent_sample(self, mu, logvar):\n",
        "        if self.training:\n",
        "            # the reparameterization trick\n",
        "            std = logvar.mul(0.5).exp_()\n",
        "            eps = torch.empty_like(std).normal_()\n",
        "            return eps.mul(std).add_(mu)\n",
        "        else:\n",
        "            return mu"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e2CrBYQU4e8r"
      },
      "source": [
        "def reconstruction_erorr(recon_x, x):\n",
        "    return functional.binary_cross_entropy(\n",
        "        recon_x.view(-1, 784),\n",
        "        x.view(-1, 784),\n",
        "        reduction = \"sum\",\n",
        "    )\n",
        "\n",
        "def vae_loss(recon_loss, mu, logvar):\n",
        "    kl_divergence = -0.5 * torch.sum(1 + logvar - mu.pow(2) - logvar.exp())\n",
        "    return recon_loss + VAR_BETA * kl_divergence"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bxImy1XR6FHR"
      },
      "source": [
        "## RRH for Gaussian Mixtures"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2H2L9XvS6Kwj"
      },
      "source": [
        "def mvn_renyi(C, q=1):\n",
        "    \"\"\" Computes the RÃ©nyi heterogeneity for a multivariate Gaussian \n",
        "    Arguments: \n",
        "        C: `ndarray((n,n))`. Covariance matrix\n",
        "        q: `0<float`. Order of the heterogeneity\n",
        "    Returns: \n",
        "        `float`\n",
        "    \"\"\"\n",
        "    n = C.shape[0]\n",
        "    SqrtDetC = np.sqrt(np.linalg.det(C))\n",
        "    if q == 1: \n",
        "        out = (2*np.pi*np.e)**(n/2) * SqrtDetC\n",
        "    elif q == np.inf: \n",
        "        out = (2*np.pi)**(n/2) * SqrtDetC\n",
        "    elif q!=1 and q!=0 and q!=np.inf:\n",
        "        out = ((2*np.pi)**(n/2))*(q**(n/(2*(q-1))))*SqrtDetC\n",
        "    return out"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TkLYVMBu6fDn"
      },
      "source": [
        "def mvn_renyi_alpha(C,  q=1):\n",
        "    \"\"\" Computes the alpha-heterogeneity for a Gaussian mixture where each sample has equal weight\n",
        "\n",
        "    Arguments: \n",
        "\n",
        "        cov: `ndarray((nsamples, n, n))`. Covariance matrices \n",
        "        q: `0<float`. Order of the heterogeneity metric\n",
        "\n",
        "    Returns: \n",
        "\n",
        "        `float`. The alpha-heterogeneity\n",
        "    \"\"\"\n",
        "    K, n, _ = C.shape\n",
        "    p = np.repeat(1/K, K)\n",
        "    if q == 1:\n",
        "        out = np.exp((n + np.sum(p*np.log(np.linalg.det(2*np.pi*C))))/2)\n",
        "    elif q!=np.inf and q!=1 and q!=0:\n",
        "        wbar = (p**q)/np.sum(p**q)\n",
        "        out = ((2*np.pi)**(n/2))*np.sum(wbar*np.sqrt(np.linalg.det(C)))/(q**(n/2))**(1/(1-q))\n",
        "    return out\n"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4aDzvMEx_X9r"
      },
      "source": [
        "def scale_to_cov(scales):\n",
        "    return np.vstack([np.expand_dims(np.diagflat(s), 0) for s in scales])"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DS7dTSHl_e2i"
      },
      "source": [
        "def pool_covariance(means, covs):\n",
        "    K = covs.shape[0] \n",
        "    p = np.repeat(1/K, K)\n",
        "    cov_ = np.einsum('ijk,i->jk', covs, p) + np.einsum('ij,ik,i->jk', means, means, p)\n",
        "    mu_ = np.einsum('ij,i->j', means, p)\n",
        "    return cov_ - np.einsum('i,j->ij', mu_, mu_)"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N7XQuBW63DmN"
      },
      "source": [
        "## VAE Training and Evaluation\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TFpBblS_eLg1"
      },
      "source": [
        "device = torch.device(\"cuda:0\" if GPU and torch.cuda.is_available() else \"cpu\")"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2FVd05s4I4YM"
      },
      "source": [
        "def plot_loss(train_losses, test_losses):\n",
        "    plt.ion()\n",
        "\n",
        "    plotlabels = [\"Total error\", \"Reconstruction error\"]\n",
        "    \n",
        "    ncols = 2\n",
        "    fig, ax = plt.subplots(ncols = ncols, figsize = (9, 2.5))\n",
        "    \n",
        "    for i in range(2): \n",
        "        ax[i].plot(train_losses[i], c = \"blue\", label = \"training\")\n",
        "        ax[i].plot(test_losses[i], c = \"red\", label = \"test\")\n",
        "            \n",
        "        ax[i].set_title(plotlabels[i])\n",
        "        \n",
        "    plt.xlabel('Epochs')\n",
        "    plt.tight_layout()\n",
        "    plt.ylabel(y)\n",
        "    plt.legend()\n",
        "    plt.show()"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "isT5TzCPJEE1"
      },
      "source": [
        "def eval_model(vae):\n",
        "    vae.eval()\n",
        "    \n",
        "    test_loss_avg, test_recon_loss_avg, num_batches = 0, 0, 0\n",
        "    for image_batch, _ in test_dataloader:\n",
        "        \n",
        "        with torch.no_grad():\n",
        "        \n",
        "            image_batch = image_batch.to(device)\n",
        "    \n",
        "            # vae reconstruction\n",
        "            image_batch_recon, latent_mu, latent_logvar = vae(image_batch)\n",
        "    \n",
        "            # reconstruction error\n",
        "            recon_loss = reconstruction_erorr(image_batch_recon, image_batch)\n",
        "            loss = vae_loss(recon_loss, latent_mu, latent_logvar)\n",
        "    \n",
        "            test_recon_loss_avg += recon_loss\n",
        "            test_loss_avg += loss.item()\n",
        "            num_batches += 1\n",
        "        \n",
        "    test_recon_loss_avg /= num_batches\n",
        "    test_loss_avg /= num_batches\n",
        "\n",
        "    return test_recon_loss_avg, test_loss_avg\n",
        "    #print('average reconstruction error: %f' % (test_recon_loss_avg))\n",
        "    #print('average error: %f' % (test_loss_avg))"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lb5IpN6M3KKk"
      },
      "source": [
        "def train_one_model(evaluate = False):\n",
        "    \"\"\" Creates and trains one VAE model.\n",
        "\n",
        "    Args:\n",
        "        evaluate: Whether or not to evaluate model during training.\n",
        "\n",
        "    Returns:\n",
        "        Tuple containing the trained model, average training reconstruction\n",
        "        error, average total training error, average testing reconstruction\n",
        "        error, and average total testing error.\n",
        "    \"\"\"\n",
        "\n",
        "    vae = VariationalAutoencoder()\n",
        "    vae = vae.to(device)\n",
        "    \n",
        "    num_params = sum(p.numel() for p in vae.parameters() if p.requires_grad)\n",
        "    print('Number of parameters: %d' % num_params)\n",
        "    \n",
        "    optimizer = torch.optim.Adam(\n",
        "        params = vae.parameters(),\n",
        "        lr = LRN_RATE,\n",
        "        weight_decay = 1e-5,\n",
        "    )\n",
        "    \n",
        "    # set to training mode\n",
        "    vae.train()\n",
        "    \n",
        "    if evaluate:\n",
        "        train_recon_loss, train_loss = [], []\n",
        "        test_recon_loss, test_loss = [], []\n",
        "    \n",
        "    print(\"Training: \", end = \"\")\n",
        "    for epoch in range(EPOCH_NUM):\n",
        "        if evaluate:\n",
        "            train_loss.append(0)\n",
        "            train_recon_loss.append(0)\n",
        "        num_batches = 0\n",
        "        \n",
        "        for image_batch, _ in train_dataloader:\n",
        "            \n",
        "            image_batch = image_batch.to(device)\n",
        "    \n",
        "            # vae reconstruction\n",
        "            image_batch_recon, latent_mu, latent_logvar = vae(image_batch)\n",
        "            \n",
        "            # reconstruction error\n",
        "            recon_loss = reconstruction_erorr(image_batch_recon, image_batch)\n",
        "            loss = vae_loss(recon_loss, latent_mu, latent_logvar)\n",
        "            \n",
        "            # backpropagation\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            \n",
        "            # one step of the optmizer (using the gradients from backpropagation)\n",
        "            optimizer.step()\n",
        "            \n",
        "            if evaluate:\n",
        "                train_loss[-1] += loss.item()\n",
        "                train_recon_loss[-1] += recon_loss\n",
        "                \n",
        "            num_batches += 1\n",
        "            \n",
        "        if evaluate:\n",
        "            train_loss[-1] /= num_batches\n",
        "            train_recon_loss[-1] /= num_batches\n",
        "        \n",
        "            recon_loss_avg, loss_avg = eval_model(vae)\n",
        "            test_recon_loss.append(recon_loss_avg)\n",
        "            test_loss.append(loss_avg)\n",
        "            vae.train()\n",
        "        \n",
        "        print(\"%d, \" % (epoch+1), end = \"\")\n",
        "        \n",
        "    print()\n",
        "    if evaluate: \n",
        "        plot_loss(\n",
        "            [train_loss, train_recon_loss],\n",
        "            [test_loss, test_recon_loss],\n",
        "        )\n",
        "        \n",
        "    return vae"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "idP_RI6bBttt"
      },
      "source": [
        "# matrix[i] is the heterogeneity array for vae_i\n",
        "# matrix[i][j] is the heterogeneity for digit_j for vae_i\n",
        "\n",
        "def train_and_test_models(\n",
        "    n, gamma_matrix, alpha_matrix, beta_matrix, evaluate = False,\n",
        "):\n",
        "    \"\"\"\n",
        "    Train n models and compute the MNIST heterogeneities on the models.\n",
        "\n",
        "    Returns:\n",
        "        Heterogeneity \"matrices\" that are lists of np arrrays.\n",
        "    \"\"\"\n",
        "    for _ in range(n):\n",
        "        vae = train_one_model(evaluate = evaluate)\n",
        "        \n",
        "        gammas, alphas, betas = calculate_rrh(vae)\n",
        "        gamma_matrix.append(gammas)\n",
        "        alpha_matrix.append(alphas)\n",
        "        beta_matrix.append(betas)\n",
        "    return gamma_matrix, alpha_matrix, beta_matrix\n",
        "\n",
        "def plot_rrh_matrices(gamma_matrix, alpha_matrix, beta_matrix):\n",
        "    gamma_avg = het_avg(gamma_matrix)\n",
        "    alpha_avg = het_avg(alpha_matrix)\n",
        "    beta_avg = het_avg(beta_matrix)\n",
        "    \n",
        "    gamma_sigma = het_sigma(gamma_matrix)\n",
        "    alpha_sigma = het_sigma(alpha_matrix)\n",
        "    beta_sigma = het_sigma(beta_matrix)\n",
        "    \n",
        "    plot_rrh(\n",
        "        gamma_avg, alpha_avg, beta_avg,\n",
        "        sigmas = [gamma_sigma, alpha_sigma, beta_sigma],\n",
        "    )"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RG67lA7u6pAY"
      },
      "source": [
        "## Compute and plot RRH for VAE"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IinU-xeM6fg_"
      },
      "source": [
        "def calculate_rrh(vae):\n",
        "    gammas = []\n",
        "    alphas = []\n",
        "    betas = []\n",
        "    for i in range(10):\n",
        "        mu, logvar = vae.encoder(torch.Tensor(X[y == i]).to(device))\n",
        "        loc = mu.cpu().detach().numpy()\n",
        "        scale = logvar.exp().cpu().detach().numpy()\n",
        "        cov = scale_to_cov(scale)\n",
        "        cov = scale_to_cov(scale)\n",
        "        gamma = mvn_renyi(pool_covariance(loc, cov), q=1)\n",
        "        alpha = mvn_renyi_alpha(cov,q=1)\n",
        "        beta = gamma/alpha\n",
        "        gammas.append(gamma)\n",
        "        alphas.append(alpha)\n",
        "        betas.append(beta)\n",
        "    return np.array(gammas), np.array(alphas), np.array(betas)"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xcRWRha365r-"
      },
      "source": [
        "def plot_rrh(gammas, alphas, betas, sigmas = None):\n",
        "    if not (len(gammas) == len(alphas) or len(gammas) == len(betas)):\n",
        "        sys.exit(\"Mismatched matrix size\")\n",
        "    n = len(gammas)\n",
        "    hetvalues = [gammas, alphas, betas]\n",
        "    plotlabels = [r\"Pooled\", r\"Within-Observation\", r\"Between-Observation\"]\n",
        "    \n",
        "    fig, ax = plt.subplots(ncols=3, figsize=(9, 2.5))\n",
        "    ax[0].set_ylabel(\"Heterogeneity\")\n",
        "    \n",
        "    for i in range(3): \n",
        "        ax[i].set_title(plotlabels[i])\n",
        "        ax[i].set_xlabel(\"Digit\")\n",
        "        ax[i].set_xticks(np.arange(10))\n",
        "        ax[i].set_xticklabels(np.arange(10))\n",
        "        ax[i].bar(\n",
        "            np.arange(10),\n",
        "            hetvalues[i],\n",
        "            facecolor = plt.get_cmap(\"Greys\")(0.4), \n",
        "            edgecolor = \"black\",\n",
        "        )\n",
        "        if not sigmas == None:\n",
        "            ax[i].errorbar(\n",
        "                np.arange(10),\n",
        "                hetvalues[i],\n",
        "                yerr = sigmas[i],\n",
        "                fmt = \"none\",\n",
        "                ecolor = \"r\",\n",
        "                capsize = 3,\n",
        "                label = \"std deviation\",\n",
        "            )\n",
        "            ax[i].errorbar(\n",
        "                np.arange(10),\n",
        "                hetvalues[i],\n",
        "                yerr = sigmas[i] / np.sqrt(n),\n",
        "                fmt = \"none\",\n",
        "                ecolor = \"b\",\n",
        "                capsize = 3,\n",
        "                label = \"std error\",\n",
        "            )\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "    #plt.savefig(\"digit-class-heterogeneity.pdf\", bbox_inches=\"tight\")"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hfwhdEx46mFx"
      },
      "source": [
        "# MNIST Experiments"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qXN-NstR42nu"
      },
      "source": [
        "## Make MNIST training and evaluation sets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R9VbzfzV47ON"
      },
      "source": [
        "img_transform = transforms.Compose([\n",
        "    transforms.ToTensor()\n",
        "])\n",
        "\n",
        "def load_mnist(train):\n",
        "    dataset = MNIST(\n",
        "        root = './data/MNIST',\n",
        "        download = True,\n",
        "        train = train,\n",
        "        transform = img_transform,\n",
        "    )\n",
        "    return DataLoader(dataset, batch_size = BATCH_SIZE, shuffle = True)\n",
        "\n",
        "train_dataloader = load_mnist(train = True)\n",
        "test_dataloader = load_mnist(train = False)"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0IMlt_q67tJo"
      },
      "source": [
        "# Place into numpy arrays for easier manipulation\n",
        "traindata = list(train_dataloader)\n",
        "traindata = [[sample[0].numpy(), sample[1].numpy()] for sample in traindata]\n",
        "X = np.vstack([sample[0] for sample in traindata])\n",
        "y = np.hstack([sample[1] for sample in traindata])"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mOOtu98Jv1-_"
      },
      "source": [
        "def het_sigma(matrix, avg = None):\n",
        "    if avg == None:\n",
        "        avg = het_avg(matrix)\n",
        "    n = len(matrix)\n",
        "    mse = (matrix[0] - avg) ** 2\n",
        "    for i in range(1, n):\n",
        "        mse += (matrix[i] - avg) ** 2\n",
        "    return np.sqrt(mse / n)\n",
        "\n",
        "def het_sum(matrix):\n",
        "    sum = matrix[0] + matrix[1]\n",
        "    for i in range(2, len(matrix)):\n",
        "        sum += matrix[i]\n",
        "    return sum\n",
        "\n",
        "def het_avg(matrix):\n",
        "    return het_sum(matrix) / len(matrix)"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eM3hF-q0VipP"
      },
      "source": [
        "# Experiments"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 311
        },
        "id": "bzmQvee5qsLp",
        "outputId": "5e23407d-2c4c-4b23-b429-74bc6f2fc318"
      },
      "source": [
        "N = 1\n",
        "n = 5\n",
        "gamma_matrix, alpha_matrix, beta_matrix = [], [], []\n",
        "for _ in range(N):\n",
        "    gamma_matrix, alpha_matrix, beta_matrix = train_and_test_models(\n",
        "        n, gamma_matrix, alpha_matrix, beta_matrix, evaluate = True,\n",
        "    )\n",
        "    plot_rrh_matrices(gamma_matrix, alpha_matrix, beta_matrix)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of parameters: 308357\n",
            "Training: 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/matplotlib/text.py:1165: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
            "  if s != self._text:\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 648x180 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Number of parameters: 308357\n",
            "Training: 1, 2, 3, 4, 5, 6, 7, 8, 9, "
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AHpfakydFLgg"
      },
      "source": [
        "N = 2\n",
        "for _ in range(N):\n",
        "    gamma_matrix, alpha_matrix, beta_matrix = train_and_test_models(\n",
        "        n, gamma_matrix, alpha_matrix, beta_matrix,\n",
        "    )\n",
        "    plot_rrh_matrices(gamma_matrix, alpha_matrix, beta_matrix"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lvx8i8Ct9yMR"
      },
      "source": [
        "## Load, Evaluate, and Plot RRH for Pre-Trained VAE"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vNRYGlvQ5O77"
      },
      "source": [
        "def load_pretrained_vae():\n",
        "    pretrained_vae = VariationalAutoencoder()\n",
        "    pretrained_vae = pretrained_vae.to(device)\n",
        "    \n",
        "    filename = 'vae_2d.pth'\n",
        "    \n",
        "    if not os.path.isdir('./pretrained'):\n",
        "        os.makedirs('./pretrained')\n",
        "    urllib.request.urlretrieve(\n",
        "        \"http://geometry.cs.ucl.ac.uk/creativeai/pretrained/\" + filename,\n",
        "        \"./pretrained/\" + filename,\n",
        "    )\n",
        "    pretrained_vae.load_state_dict(torch.load('./pretrained/' + filename))\n",
        "    return pretrained_vae"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nRS4NG0mJJZY"
      },
      "source": [
        "pretrained_vae = load_pretrained_vae()\n",
        "eval_model(pretrained_vae)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_nN1Kftyh42Z"
      },
      "source": [
        "gammas, alphas, betas = calculate_rrh(pretrained_vae)\n",
        "plot_rrh(gammas, alphas, betas)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}